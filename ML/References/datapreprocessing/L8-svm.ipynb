{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== Nguồn http://users.soict.hust.edu.vn/khoattq/ml-dm-course/ ======\n",
    "\n",
    "\n",
    "# Bài toán phân loại sử dụng SVM \n",
    "\n",
    "Mục tiêu: \n",
    "- Xây dựng được mô hình svm sử dụng thư viện sklearn. \n",
    "- Ứng dụng, hiểu cách áp dụng mô hình SVM vào giải quyết bài toán thực tế (Ví dụ: phân loại văn bản) \n",
    "- Sử dụng độ đo Accuracy để làm độ đo đánh giá chất lượng mô hình. \n",
    "\n",
    "Dữ liệu: \n",
    "- Có tập các văn bản và nhãn tương ứng của từng văn bản trong một khoảng thời gian \n",
    "- Tập các nhãn (10 nhãn khác nhau): \n",
    "    > Giải trí, Khoa học - Công nghệ, Kinh tế, Pháp luật, Sức khỏe, Thể thao, Thời sự, Tin khác, Độc giả, Đời sống - Xã hội\n",
    "- Ví dụ văn bản nhãn **thể thao**: \n",
    "    > \"Dân_trí Real Madrid đã dẫn trước trong cả trận đấu , nhưng họ vẫn phải chấp_nhận bị Dortmund cầm hòa 2-2 ở Bernabeu . Real Madrid chấp_nhận đứng thứ_hai ở bảng F Champions League ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dữ liệu từ thư mục đã thu thập từ trước \n",
    "\n",
    "Giả sử cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_1135/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/news_vnexpress/\"\n",
    "header = \"%-20s%-30s\" % (\"Số lượng văn bản\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "total = 0\n",
    "for label in os.listdir(DATA_PATH):\n",
    "    n = len(os.listdir(os.path.join(DATA_PATH, label)))\n",
    "    total += n\n",
    "    entry = \"%-20d%-30s\" % (n, label)\n",
    "    print(entry)\n",
    "print(\"---------------------------------------------\")\n",
    "print(f'Tổng số văn bản: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_files(container_path=DATA_PATH, encoding=\"utf-8\")\n",
    "print(dir(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"%-6s %-10s\" % (\"ID\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "for id, label in enumerate(data_train.target_names):\n",
    "    print(\"%-6d %-10s\" % (id, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.data[0:2], end='\\n\\n')\n",
    "print(data_train.filenames[0:2], end='\\n\\n')\n",
    "print(data_train.target[0:2], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Kiểm tra các thông tin sau:\n",
    "    + Số lượng văn bản trong data_train.data\n",
    "    + Số lượng ids trong data_train.target\n",
    "    + Số lượng filenames trong data_train.filenames\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tiền xử lý dữ liệu: đưa dữ liệu từ dạng text về dạng ma trận bằng TF-IDF\n",
    "\n",
    "- Thử nghiệm để kiểm tra hoạt động chuyển hoá dữ liệu về dạng ma trận "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords]\n",
    "print(f\"Tổng số lượng từ dừng: {len(stopwords)}\")\n",
    "print(\"Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại): \", stopwords[:10])\n",
    "print()\n",
    "\n",
    "\"\"\"\n",
    "Chuyển hoá dữ liệu text về dạng vector tfidf \n",
    "    - loại bỏ từ dừng\n",
    "    - sinh từ điển\n",
    "    - chuyển thành dữ liệu dạng ma trận 2 chiều kích thước n x m với n là số lượng văn bản và m là số lượng từ trong từ điển\n",
    "\"\"\"\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "print(\"5 từ đầu tiên trong từ điển:\\n\")\n",
    "i = 0\n",
    "for k,v in module_count_vector.vocabulary_.items():\n",
    "    i+=1\n",
    "    print(i, \": \", (k, v))\n",
    "    if i > 5:\n",
    "        break \n",
    "print()\n",
    "\n",
    "# Số chiều của dữ liệu \n",
    "print(f\"Số chiều của dữ liệu: {data_preprocessed.shape}\")\n",
    "print(f\"Số từ trong từ điển: {len(module_count_vector.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia dữ liệu thành 2 phần train_data và test_data\n",
    "- train_data chiếm 80 % dữ liệu \n",
    "- test_data chiếm 20 % dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# chia dữ liệu thành 2 phần sử dụng hàm train_test_split.\n",
    "test_size = 0.2\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split( data_preprocessed, data_train.target, test_size=test_size)\n",
    "\n",
    "\n",
    "# hiển thị một số thông tin về dữ liệu \n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Hiển thị ra id, tên nhãn của 5 văn bản đầu tiên trong tập train. \n",
    " - Gợi ý: lấy dữ liệu id từ biến y_train, mapping với thứ tự nằm trong mảng data_train.target_names\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Huấn luyện mô hình SVM trên tập train_data\n",
    "\n",
    "Sử dụng thư viện sklearn để xây dựng mô hình \n",
    "- `svm.SVC(kernel='linear', C=1.0)`: chọn hàm nhân phân tách là linear, tham số C=1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Đánh giá mô hình SVM trên tập test_data\n",
    "\n",
    "Thực hiện dự đoán nhãn cho từng văn bản trong tập test_data \n",
    "\n",
    "Độ đo đánh giá: \n",
    "> accuracy = tổng số văn bản dự đoán đúng  / tổng số văn bản có trong tập test_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng model đã được huấn luyện để phán đoán 1 văn bản mới \n",
    "- Dữ liệu mới đến ở dạng dữ liệu thô => cần tiền xử lý dữ liệu về dạng dữ_liệu_ma_trận\n",
    "- Phán đoán bằng hàm model.predict(dữ_liệu_ma_trận) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiền xử lý dữ liệu sử dụng module model_rf_preprocess. \n",
    "news = [\"Công_phượng ghi bàn cho đội_tuyển Việt_nam\"]\n",
    "preprocessed_news = model_rf_preprocess.transform(news)\n",
    "print(preprocessed_news, end='\\n\\n')\n",
    "# phán đoán nhãn\n",
    "pred = model.predict(preprocessed_news)\n",
    "print(pred, data_train.target_names[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bài tập bổ sung: \n",
    "\n",
    "### 4.1 Thử nghiệm các tham số \n",
    "\n",
    "- Các tham số với giá trị khác nhau có thể ảnh hưởng để kết quả học \n",
    "- Cần thử nghiệm kỹ lượng để đưa ra kết quả khách quan: tham số C, kernel.\n",
    "    - Chọn mô hình với bộ tham số cho kết quả tốt nhất "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM: kernel, C\n",
    " - Gợi ý:\n",
    "     + Đầu tiên cố định C = 1.0 (có thể là giá trị khác), thay đổi kernel = {'linear', 'poly', 'rbf', 'sigmoid'}\n",
    "     + Với mỗi kernel chạy huấn luyện và đánh giá lại mô hình. Chọn kernel cho acc cao nhất.\n",
    "       Giả sử trong trường hợp này là linear\n",
    "     + Cố định kernel là linear, thay đổi C = {0.1, 1.0, 5.0, 10.0}\n",
    "     + Với mỗi giá trị C chạy huấn luện và đánh giá lại. Chọn C cho acc cao nhất.\n",
    "\"\"\"\n",
    "######################\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Phân loại số viết tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "target = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=test_size)\n",
    "\n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM với bài toán phân loại ảnh\n",
    " - Gợi ý: Làm tương tự với phân loại văn bản phía trên\n",
    "\"\"\"\n",
    "######################\n",
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
